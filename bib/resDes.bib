@InProceedings{Bai2022AAAI,
  title={Towards End-to-End Image Compression and Analysis with Transformers},
  author={Bai, Yuanchao and Yang, Xu and Liu, Xianming and Jiang, Junjun and Wang, Yaowei and Ji, Xiangyang and Gao, Wen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@article{jiang2021transgan,
  title={Transgan: Two pure transformers can make one strong gan, and that can scale up},
  author={Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@misc{Principles,
  url = {https://arxiv.org/abs/2204.01782},
  author = {Ehrlich, Max},
  title = {The First Principles of Deep Learning and Compression},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{Metrics,
  title = {Module: metrics - skimage},
  author = {Scikit-Image Documentation},
  howpublished = {\url{https://scikit-image.org/docs/stable/api/skimage.metrics.html}},
  year = {2022},
  note = {Accessed: 2022-04-30}
}

@ARTICLE{BRISQUE,
  author={Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan Conrad},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Image Quality Assessment in the Spatial Domain}, 
  year={2012},
  volume={21},
  number={12},
  pages={4695-4708},
  doi={10.1109/TIP.2012.2214050}}

@inproceedings{Attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{PapersOverTime,
  title = {Vision Transformer Explained},
  author = {PapersWithCode},
  howpublished = {\url{https://paperswithcode.com/method/vision-transformer}},
  year = {2022},
  note = {Accessed: 2022-04-30}
}

@misc{GPT3,
  title = {OpenAI's GPT-3 Language Model: A Technical Overview},
  author = {Chuan Li},
  howpublished = {\url{https://lambdalabs.com/blog/demystifying-gpt-3/}},
  year = {2022},
  note = {Accessed: 2022-04-30}
}


@misc{Dalle2,
  title = {Dall.E 2},
  author = {OpenAI},
  howpublished = {\url{https://openai.com/dall-e-2/}},
  year = {2022},
  note = {Accessed: 2022-04-30}
}