\section{Results and Improvements}
We will review the merits from this work.

\subsection{Results}

Features are in deep layers of the GAN network. 
Latent space is hard to decipher
ViT score definition: how many of the top100 labels match
Can take into account probability of label (included in ViT).
While label probability is stable when working with corrupted images (demo), 
unstable when working with generated images.

\subsection{Potential Improvements to Architecture}

Analyze latent space vector with transformer model (not a ViT, but a transformer adaptation)
Steer the GAN faster into training to compress
Slow computational times
Need a GAN trained on all images, not just ImageNet or Celeb 
Need ViT trained on all images
Natural limit to capacity of this model comes from training sets.



\newpage
\section{Present and Future of Image Transformers}
Status quo of Transformers in Image Processing, Compression, Analysis, and Generation
Coveted Deep learning based Image compression 
In the deep learning/AI evolutionary process, still too early. Models have not been trained on enough image data.

GAN model only trained on finite set (ImageNet, CIFAR-10, Celeb-HQ faces etc) and resolution.
Need to train GAN on all images ever.


\section{Training and Cost Estimates}

Need a ViT on all internet to cost 100M
A 512-core TPU v3 pod costs \$384/hr to use commercially on GCP. 
2.5k core-days means training the ViT cost 24hrs * \$384 * 5 of them = \$46k. 
That's for one of many ViT flavors.
To train a ViT on the whole TACC Frontera at 20k teraflops (top10) or 
Stampede at 10k tflops (top25), it would take respectively about a minute and 2 minutes.
tpu v3 is 420 teraflops * 2500 = 1M Tflops

(like GPT-3 trained on all internet text, Vision T trained on all google images)

(\$100M+), GPT-3 cost \$10M-\$20M