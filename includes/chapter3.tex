\section{Architecture and Inputs}

\subsection{General Project Architecture}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=1\textwidth]{media/main_arch2.png}
	\end{center}
	\caption[Model Architecture]{The engine architecture for this project. A GAN compresses and reconstructs
    an input image. Then, a Vision Transfomer (ViT) conducts object detection in both the input and generated images.
    Finally, the ViT-Score is computed based on the number of matching labels.}
	\end{figure}

A standard Generator-Discriminator architecture GAN was used. 

The Generator generates a synthetic image for the Discriminator to evaluate.
Stochastic Gradient Descent (SGD) optimizer was used for the GAN to find the most optimal latent space vector
representation of the input image.
Mean Squared Error (MSE) was used as a Loss function.

A pre-trained Vision Transformer (ViT) was used for the image labeling.


\subsection{Image Compression Diagram}

Similar to established image compression methodologies, the compression and reconstruction process 
is divided into a Compressor and Decompressor parts.

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.6\textwidth]{media/main_compress.png}
	\end{center}
	\caption[Compression Architecture]{The Compressor-Decompressor uses the GAN Generator from Figure 3.1 above 
    to generate the output image using most optimal latent vector representation.}
	\end{figure}

As showing in Figure 3.2 above, the Compressor is composed of the GAN Generator and an input image to find and return the latent vector using
Stochastic Gradient Descent (SGD).

The Decompressor then uses the GAN Generator and latent vector from the Compressor to produce the final reconstructed image.


Following the Decompressor generating an output image, the pre-trained ViT then detects objects from a 
dictionary of labels. The ViT outputs a probability distribution, i.e. a probability for each label summing to unity (softmax). 
The final output of the script developed for this project is the ViT-Score, and other relevant image quality metrics (e.g. SSIM, MSE, etc)
to evaluate the generated output image.

Python and PyTorch were used for the implementation of the architectures detailed above.

\subsection{Sample Input Images Used}


Four images (512x512, PNG format) are used in this study.
The images represent distinct types of image to be compressed, as well as 
diverse features to challenge the deep learning model architecture.
For example, a white background ("Logo"), a black background ("Bevo"), similar shapes, but
distinct images ("Logo" vs "Bevo"), a face, a building, trees and clouds in the background.


\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.7\textwidth]{media/input_images_labeled.png}
	\end{center}
	\caption[Input Images]{Input Images used in this project (512x512):

    \hspace{2cm} "Bevo": The University of Texas mascot, a famous longhorn bull.

    \hspace{2cm} "Kliment": A face portrait of the author. 

    \hspace{2cm} "Logo": The Texas Longhorns logo.
    
    \hspace{2cm} "Tower": The University of Texas Tower, the Main Building on campus.}
	\end{figure}


\subsection{Latent space vector representation during compression}

$nx1$ vector, where $n$ corresponds to the height or width (in pixels)
of a square input image. In the case of all input images used, the latent vector
is of size $512x1$, since the input images are of size $512x512$.

hard to decipher but here is a zoomed in visual of the first
This is what the GAN architecture compresses the full image to (1.54kb vs original size 409kb).
The GAN then rebuils to 242kb.


\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.5\textwidth]{media/latent.png}
	\end{center}
	\caption[Latent Space Representation]{Visual representation of the first 10 pixels in the most compressed version of the original image.}
	\end{figure}

% \newpage
\section{Outputs and Visual Inspection}
The generative process from the GAN was designed to output an image at a specified epoch.

\subsection{Training Process}
Below is a demonstration of the GAN learning process at every 250 epochs:
\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/ganLearn.png}
	\end{center}
	\caption[GAN Training Process]{The GAN learns to compress and generate the Texas Longhorns logo.}
	\end{figure}

Due to the cutting edge nature of the technologies used, a natural performance asymptote
was observed. The GAN was able to reconstruct certain input images better than others.
After a certain iteration, as usual, the GAN was unable to further learn how to compress,
represent, and regenerate some input images. Typically, once a GAN reaches this stage,
it learns from random noise and generation performance decreases.

\subsection{Generated Results}

Figure 3.4 below shows the resulting images from the neural compression GAN.

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/gan_compress2.png}
	\end{center}
	\caption[Neural Compression and Generation]{After sufficient training, the GAN outputs a regenerated
    version of the original image from a latent space vector representation.}
	\end{figure}

\vspace{5mm}   


The GAN was able to respectably regenerate "Kliment" and "Logo", especially if the resolution
were to be lowered (e.g. 32x32, such as the CIFAR-10 dataset).

However, the GAN was unable to perform as well for "Bevo" and "Tower".
It learned random noise and generation performance decreased.


\textbf{Compression Ratios (CR)}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Bevo}	& 1.32 \textit{(failed to compress)}\\
\textbf{Kliment}	& 0.59\\
\textbf{Logo}	& 8.28 \textit{(failed to compress)}\\
\textbf{Tower} & 0.54\\\hline

\end{tabular}
\caption[Results: Compression Ratios]{Compression ratios of generated images.}
\end{center}
\end{table}

The GAN failed to compress two of the images, "Bevo" and "Logo". Understandably,
"Logo" is actually a vector graphic with a clear background, with an input file size of only 13.4 KB.
The GAN had to create the white background, which cost extra disk space.

"Kliment" and "Tower" were compressed to half the original size, with "Kliment"
being a suitable candidate to demonstrate the capacity of this GAN.
Much like the content of "Kliment", the most popular application and training set of most GANs, including this pre-trained model,
is indeed faces. Hence, "Kliment" had the highest Compression Ratio (CR), while maintaining the highest ViT-Score.


\section{ViT-Scores}

The Vision Transformer-Assisted ViT Score is an original development from this thesis. 

It is an attempt to measure the quality of a generated image after neural compression.

The ViT-score is in the open interval $(0,1)$ with $0$ being poor and extremely dissimilar from
the original and $1$ being excellent and fully similar to original.

Mathematically, the endpoint values of the interval are unattainable by probabilistic models
such as the GAN.

\subsection{Mathematical Formulation}

The following is a mathematical representation explained in further detail.

\begin{center}
    $ViT_{score} = \displaystyle\dfrac{argmax_{A'\subset A,\lvert A' \rvert = k } \sum_{a \in A'} {a} }{k} $
\end{center}

\vspace{1mm}

\begin{center}
where $\sum_{a \in A'} {a}  = \lbrace{m \in I_{input}}\rbrace \cap \lbrace{n \in I_{generated}}\rbrace$
\end{center}

\vspace{2mm}

and $m$ are the top-$K$ labels in the input image $I_{input}$

and $n$ are the top-$K$ labels in the generated image $I_{generated}$.

\vspace{4pt}

This overly elaborate mathematical notation is an attempt at describing:


\NOTE{
"From the full set of trained ViT labels, we find the top-$K$ number of intersecting labels between the original and generated images. Then, we divide that by $K$"
}


For example, of the top-100 labels found in the original image, 
identify the set of labels also found in the generated image. 
Then, divide that number of intersecting
labels by the total number of 100 labels.


\subsection{ViT-Scores from Resulting Images}


Following Figure 3.7, the ViT-scores for the GAN generated images after neural compression
are as follows:

\begin{center}
	\includegraphics[width=0.6\textwidth]{media/gan_compress2.png}

    \textbf{Resulting generated images.}
\end{center}

\textbf{ViT-Scores}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Bevo}	& 0.14\\
\textbf{Kliment}	& 0.54\\
\textbf{Logo}	& 0.29\\
\textbf{Tower} & 0.03\\\hline

\end{tabular}
\caption[ViT-Scores of Generated Images]{ViT-Scores demonstrate a somewhat expected quality assessment.}
\end{center}
\end{table}



\textbf{"Kliment"} leads with a ViT-score of $0.54$, which is understandable as the GAN 
generated a face (although smudgy) and was rather able to recreate the scenery structurally.

\textbf{"Logo"} generation seems structurally excellent and the ViT-score is $0.29$, which
is considered a good score for this particular GAN architecture and training.

\textbf{"Bevo"} barely preserves the original shape at ViT-score of $0.14$, while
\textbf{"Tower"} is incomprehensible and barely resembles the original at ViT-score of $0.03$.


Overall, the ViT-score does a good job of measuring image quality.


\section{Established IQA Metrics}

\subsection{"Kliment"}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/kimbo_metrics.png}
	\end{center}
	\caption["Kliment" Established Metrics]{The image was structurally reconstructed rather well.
    Shortcomings were only the facial features within the face.}
	\end{figure}


This image achieved a ViT-Score of 0.54, SSIM of 0.56, and MSE of 1,759.28 with a Compression Ratio of 0.59.

\subsection{"Logo"}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/logo_metrics.png}
	\end{center}
	\caption["Logo" Established Metrics]{The GAN was able to reconstruct the logo almost perfectly.}
	\end{figure}


    The generated logo is extremely well identifiable.
    This image achieved a ViT-Score of 0.29, SSIM of 0.91, and MSE of 393.69. However, it failed to be compressed
    less than its original size. The GAN had to reconstruct the white background, which came out yellowish.

\subsection{"Bevo"}

\begin{figure}[H]
        \begin{center}
        \includegraphics[width=0.8\textwidth]{media/bevo_metrics.png}
        \end{center}
        \caption["Bevo" Established Metrics]{The GAN was unable to reconstruct inside the longhorn, yet
        the structure of the image is well rebuilt. One could possibly identify the animal from the generated image.}
        \end{figure}

"Bevo" achieved a ViT-Score of 0.14, SSIM of 0.26, and MSE of 3,479.34, while failing to compress. 

\subsection{"Tower"}

\begin{figure}[H]
        \begin{center}
        \includegraphics[width=0.8\textwidth]{media/tower_metrics.png}
        \end{center}
        \caption["Tower" Established Metrics]{The GAN completely failed at .}
        \end{figure}

This reconstruction is the lowest quality of all four images, both quantitatively and qualitatively.
The generated image is incomprehensible. It has the lowest ViT-Score at 0.03, SSIM of 0.53, and MSE of 1,315.75.

\subsection{"BRISQUE"}

Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE)
where approaching 0 is a good score and approaching 100 is a bad score, the BRISQUE referenceless 
image quality methodology

This score could be interpreted as the image being more photorealistic than not. 
In terms of quality, this compares to a camera captured image with quality corruption 
caused by blurs or graininess. An image with no distortions often has a score below 5.

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
      & Original & Generated \\ [0.5ex] 
    \hline\hline
    \textbf{Bevo}	& 32.9214 & 39.5535\\
    \textbf{Kliment}	& -8.3593 & 44.3570\\
    \textbf{Logo}	& 102.9010 & 97.1844\\
    \textbf{Tower} & 14.5973 & 52.8363\\\hline
    
    \end{tabular}
    \caption[BRISQUE]{BRISQUE Scores of original and generated images.}
    \end{center}
    \end{table}

Expectedly, the BRISQUE values for the generated images are always higher than
their original counterparts. "Logo" is not a photorealistic image to begin with, 
so it is understandable that the BRISQUE value is high at $102.9$.
None of the generated images would pass BRISQUE as photorealistic and free of 
distortions.  

Loss functions as well (MSE loss was used in GAN)


\subsection{GAN-Related Quantitative Metrics}

There are two prominent evaluation metrics for the performance of a Generative Adversarial Network (GAN).
Specifically, the Frechet Inception Distance (FID) and Inception Score (IS).

The FID score is 0 if there is no difference between the two multidimensional Gaussian distributions compared. 

Both measurements serve to evaluate the synthetic nature of the generated output. 


The \textbf{FID} score is presented in Table 3.1 below:

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
        \hline
    \textbf{Bevo}	& 1,241,999.901 \\
    \textbf{Kliment}	& 549,089.491\\
    \textbf{Logo}	& 81,105.162\\
    \textbf{Tower} & 331,171.556\\\hline
    
    \end{tabular}
    \caption[FID Score]{The Frechet Inception Distance (FID) score for all test images.}
    \end{center}
    \end{table}


The FID score can be used as a Loss functions as well, embedded within the architecture of the GAN.
However, it provides notoriously incosistent results, and is not as robut as MSE, which was used as 
the Loss function of choice for this project.

\section{Summary of Results}

\begin{center}
	\includegraphics[width=0.8\textwidth]{media/gan_compress2.png}
\end{center}

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    \textbf{Image}	& \textbf{ViT-Score} & \textbf{SSIM} & \textbf{MSE} & \textbf{PSNR} & \textbf{FID}  & \textbf{BRISQUE} & \textbf{CR}\\
    \hline
    \textbf{Bevo}	 & 0.14 & 0.26 & 3,479.34  &  12.68  &  1,241,999.901  &  39.5535 & 1.32 \\
    \textbf{Kliment} & 0.54 & 0.56 & 1,759.28 & 15.64  &  549,089.491 & 44.3570 & 0.59\\
    \textbf{Logo}	 & 0.29 & 0.91 & 393.69 & 22.15 &  81,105.162 & 97.1844 & 8.28 \\
    \textbf{Tower}   & 0.03 & 0.53 & 1,315.75 & 16.90 &  331,171.556 & 52.8363 & 0.54\\\hline
    
    \end{tabular}
    \caption[Summary of Results]{ViT-Scores provide an insightful quality assessment compared to established methods.}
    \end{center}
    \end{table}
