\section{Architecture}

\subsection{Main Components}

The main architectural components of this project are a Generative Adversarial Network (GAN) and a Vision Transformer (ViT).
An input image is compressed into a latent vector form, which is then used to generate a synthetic version of the original image.
The GAN iteratively improves its ability to generate a realistic image, which resembles the input (refer to Section 2.3 for an overview of GANs).
A pre-trained "PGAN" was used, further described in Section 3.1.3.

A pre-trained Vision Transformer (ViT) was used for object detection in both the input and reconstructed images. 
A custom method then identifies the number of matching labels between the images. Finally, a ViT-Score is computed. 

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=1\textwidth]{media/main_arch2.png}
	\end{center}
	\caption[Model Architecture]{The full ViT-Scoring engine. A GAN compresses, then reconstructs
    an input image from its latent vector. Then, a Vision Transfomer (ViT) detects objects in the input and generated images.
    Finally, the ViT-Score is computed from the number of matching labels.}
	\end{figure}

\subsection{Image Compression Diagram}


Stochastic Gradient Descent (SGD) optimizer was used for the GAN to find the most optimal latent vector representation of the input image.
Mean Squared Error (MSE) was used as a Loss function to improve the GAN performance.

Similar to established image compression methodologies, the compression and reconstruction process 
is divided into a Compressor and Decompressor parts.

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.6\textwidth]{media/main_compress.png}
	\end{center}
	\caption[Compression Architecture]{The Compressor-Decompressor uses the GAN Generator from Figure 3.1 above 
    to generate the output image using most optimal latent vector representation.}
	\end{figure}

As showing in Figure 3.2 above, the Compressor is composed of the GAN Generator and an input image to find and return the latent vector using
Stochastic Gradient Descent (SGD).

The Decompressor then uses the GAN Generator and latent vector from the Compressor to produce the final reconstructed image.


Following the Decompressor generating an output image, the pre-trained ViT then detects objects from a 
dictionary of labels it has been trained on. The ViT outputs a probability distribution, i.e. a probability for each label summing to unity (Softmax, refer to Section 1.4.2). 
The final output of the script developed for this project is the ViT-Score, and other relevant image quality metrics (e.g. SSIM, MSE, etc)
to evaluate the generated output image.

A PyTorch implementation of the ViT was used, trained on ImageNet-21k and fine tuned on ImageNet-1k (refer to Section 1.5.1).

Python and Python libraries were used throughout the implementation of the architectures described above (see Appendix A for details).

\subsection{The GAN}

A standard Generator-Discriminator GAN architecture, called a "PGAN" (Progressive Growing of GAN), was used from a pre-trained model.
The model was trained on three major datasets: "celebaHQ", "fashionGen", and "DTD". 
"CelebaHQ" is a dataset of celebrity faces. "FashionGen" is a set of fashion objects such as clothing and accessory items.
"DTD" (Describable Textures Dataset) is a collection of textures such as checkered patterns, foods, and animal fur.
\citep{PytorchGANZoo}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.7\textwidth]{media/pgan.png}
	\end{center}
	\caption[The pre-trained "PGAN"]{The pre-trained "PGAN" by Facebook-Research, implemented in PyTorch. 
    It is trained on three diverse datasets of objects.\citep{PytorchGANZoo}}
	\end{figure}

\NOTE{The presumption is that since a "PGAN" is trained on these three diverse datasets, it should, in principle, be able to compress 
and reconstruct any input image. Its output however, may vary significantly, depending on the complexity of the input.}

\subsection{Latent space vector representation}

A square input image entering the compression engine is compressed to a $nx1$ vector, where $n$ corresponds to the height or width (in pixels)
of the image. In the case of all input images used in this project, the latent vector
is of size $512x1$, since the input images are of size $512x512$.

The exact meaning of the vector is hard to decipher. Figure 3.4 below shows a sample of the compressed image vector representation:

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.4\textwidth]{media/latent.png}
	\end{center}
	\caption[Latent Space Representation]{Visual representation of the first 10 pixels of the most compressed form of the original image.}
	\end{figure}

The figure above demonstrates what the GAN architecture compresses the full image to. In this case, an original image 
of size $409$ kilobytes was compressed to a $1.54$ kilobyte image vector. 

The resulting Compression Ratio (CR) is $266:1$.
Such a Compression Ratio is an order of magnitude higher than deterministic compression algorithms would ever be able to achieve. 
\citep{Principles}

The GAN then proceeds to rebuild the image to 242kb. The final Compression Ratio is $1.69$.
% \newpage
\subsection{Sample Input Images Used}

Four images of size 512x512, in PNG format are used in this study.
These images represent distinct types of image to be compressed, containing 
diverse features, in order to challenge the model architecture.

For example, one image ("Logo") contains a white background, while another ("Bevo") a black background.
The two completely dissimilar images, "Logo" and "Bevo", also happen to contain similar shapes, representing a graphic and a living
Texas longhorn bull.
The image "Kliment", a portait of the author, contains a face with trees and clouds in the background.

The image "Tower" is a building, the University of Texas at Austin Main Tower, containing
trees in the foreground, but clouds in the background.

\NOTE{This set of four images was carefully chosen to represent similarities and dissimilarities in order to 
test the robustness of the ViT-Score and capacity of the Vision Transformer itself.}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.5\textwidth]{media/input_images_labeled.png}
	\end{center}
	\caption[Input Images]{Input Images used in this project (512x512):

    \hspace{2cm} "Bevo": The University of Texas mascot, a famous longhorn bull.

    \hspace{2cm} "Kliment": A face portrait of the author. 

    \hspace{2cm} "Logo": The Texas Longhorns logo.
    
    \hspace{2cm} "Tower": The University of Texas Tower, the Main Building on campus.}
	\end{figure}


\section{Outputs and Visual Inspection}
The generative process from the GAN was designed to output an image at a specified epoch.

\subsection{Training Process}
Below is a demonstration of the GAN learning process at every 250 epochs:
\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/ganLearn.png}
	\end{center}
	\caption[GAN Training Process]{The GAN learns to compress and generate the Texas Longhorns logo.}
	\end{figure}

Due to the cutting edge nature of the technologies used, a natural performance asymptote
was observed. The GAN was able to reconstruct certain input images better than others.
After a certain iteration, as usual, the GAN was unable to further learn how to compress,
represent, and regenerate some input images. Typically, once a GAN reaches this stage,
it learns from random noise and generation performance decreases.

\subsection{Generated Results}

Figure 3.4 below shows the resulting images from the neural compression GAN.

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/gan_compress2.png}
	\end{center}
	\caption[Neural Compression and Generation]{After sufficient training, the GAN outputs a regenerated
    version of the original image from a latent space vector representation.}
	\end{figure}

\vspace{5mm}   


The GAN was able to respectably regenerate "Kliment" and "Logo", especially if the resolution
were to be lowered (e.g. 32x32, such as the CIFAR-10 dataset).

However, the GAN was unable to perform as well for "Bevo" and "Tower".
It learned random noise and generation performance decreased.


\textbf{Compression Ratios (CR)}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Bevo}	& 0.75 \textit{(failed to compress)}\\
\textbf{Kliment}	& 1.69\\
\textbf{Logo}	& 0.12 \textit{(failed to compress)}\\
\textbf{Tower} & 1.85\\\hline

\end{tabular}
\caption[Results: Compression Ratios]{Compression ratios of generated images.}
\end{center}
\end{table}

The GAN failed to compress two of the images, "Bevo" and "Logo". Understandably,
"Logo" is actually a vector graphic with a clear background, with an input file size of only 13.4 KB.
The GAN had to create the white background, which it inefficiently stores as information, costing extra 
bandwidth and disk space.

"Kliment" and "Tower" were compressed to half the original size, with "Kliment"
being a suitable candidate to demonstrate the capacity of this GAN.
Much like the content of "Kliment", the most popular application and training set of most GANs, including this pre-trained model,
is indeed faces. Hence, "Kliment" had the highest Compression Ratio (CR), while maintaining the highest ViT-Score.


\section{ViT-Scores}

The Vision Transformer-Assisted ViT Score is an original development from this thesis. 

It is an attempt to measure the quality of a generated image after neural compression.

The ViT-score is in the open interval $(0,1)$ with $0$ being poor and extremely dissimilar from
the original and $1$ being excellent and fully similar to original.

Mathematically, the endpoint values of the interval are unattainable by probabilistic models
such as the GAN.

\subsection{Mathematical Formulation}

The following is a mathematical representation explained in further detail.

\begin{center}
    $ViT_{score} = \displaystyle\dfrac{argmax_{A'\subset A,\lvert A' \rvert = k } \sum_{a \in A'} {a} }{k} $
\end{center}

\vspace{1mm}

\begin{center}
where $\sum_{a \in A'} {a}  = \lbrace{m \in I_{input}}\rbrace \cap \lbrace{n \in I_{generated}}\rbrace$
\end{center}

\vspace{2mm}

and $m$ are the top-$K$ labels in the input image $I_{input}$

and $n$ are the top-$K$ labels in the generated image $I_{generated}$.

\vspace{4pt}

This overly elaborate mathematical notation is an attempt at describing:


\NOTE{
"From the full set of trained ViT labels, we find the top-$K$ number of intersecting labels between the original and generated images. Then, we divide that by $K$"
}


For example, of the top-100 labels found in the original image, 
identify the set of labels also found in the generated image. 
Then, divide that number of intersecting
labels by the total number of 100 labels.


\subsection{ViT-Scores from Resulting Images}


Following Figure 3.7, the ViT-scores for the GAN generated images after neural compression
are as follows:

\begin{center}
	\includegraphics[width=0.6\textwidth]{media/gan_compress2.png}

    \textbf{Resulting generated images.}
\end{center}

\textbf{ViT-Scores}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Bevo}	& 0.14\\
\textbf{Kliment}	& 0.54\\
\textbf{Logo}	& 0.29\\
\textbf{Tower} & 0.03\\\hline

\end{tabular}
\caption[ViT-Scores of Generated Images]{ViT-Scores demonstrate a somewhat expected quality assessment.}
\end{center}
\end{table}



\textbf{"Kliment"} leads with a ViT-score of $0.54$, which is understandable as the GAN 
generated a face (although smudgy) and was rather able to recreate the scenery structurally.

\textbf{"Logo"} generation seems structurally excellent and the ViT-score is $0.29$, which
is considered a good score for this particular GAN architecture and training.

\textbf{"Bevo"} barely preserves the original shape at ViT-score of $0.14$, while
\textbf{"Tower"} is incomprehensible and barely resembles the original at ViT-score of $0.03$.


Overall, the ViT-score does a good job of measuring image quality.


\section{Established IQA Metrics}

\subsection{"Kliment"}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/kimbo_metrics.png}
	\end{center}
	\caption["Kliment" Established Metrics]{The image was structurally reconstructed rather well.
    Shortcomings were only the facial features within the face.}
	\end{figure}


This image achieved a ViT-Score of 0.54, SSIM of 0.56, and MSE of 1,759.28 with a Compression Ratio of 0.59.

\subsection{"Logo"}

\begin{figure}[H]
	\begin{center}
	\includegraphics[width=0.8\textwidth]{media/logo_metrics.png}
	\end{center}
	\caption["Logo" Established Metrics]{The GAN was able to reconstruct the logo almost perfectly.}
	\end{figure}


    The generated logo is extremely well identifiable.
    This image achieved a ViT-Score of 0.29, SSIM of 0.91, and MSE of 393.69. However, it failed to be compressed
    less than its original size. The GAN had to reconstruct the white background, which came out yellowish.

\subsection{"Bevo"}

\begin{figure}[H]
        \begin{center}
        \includegraphics[width=0.8\textwidth]{media/bevo_metrics.png}
        \end{center}
        \caption["Bevo" Established Metrics]{The GAN was unable to reconstruct inside the longhorn, yet
        the structure of the image is well rebuilt. One could possibly identify the animal from the generated image.}
        \end{figure}

"Bevo" achieved a ViT-Score of 0.14, SSIM of 0.26, and MSE of 3,479.34, while failing to compress. 

\subsection{"Tower"}

\begin{figure}[H]
        \begin{center}
        \includegraphics[width=0.8\textwidth]{media/tower_metrics.png}
        \end{center}
        \caption["Tower" Established Metrics]{The GAN completely failed at .}
        \end{figure}

This reconstruction is the lowest quality of all four images, both quantitatively and qualitatively.
The generated image is incomprehensible. It has the lowest ViT-Score at 0.03, SSIM of 0.53, and MSE of 1,315.75.

\subsection{"BRISQUE"}

Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE)
where approaching 0 is a good score and approaching 100 is a bad score, the BRISQUE referenceless 
image quality methodology

This score could be interpreted as the image being more photorealistic than not. 
In terms of quality, this compares to a camera captured image with quality corruption 
caused by blurs or graininess. An image with no distortions often has a score below 5.

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
      & Original & Generated \\ [0.5ex] 
    \hline\hline
    \textbf{Bevo}	& 32.9214 & 39.5535\\
    \textbf{Kliment}	& -8.3593 & 44.3570\\
    \textbf{Logo}	& 102.9010 & 97.1844\\
    \textbf{Tower} & 14.5973 & 52.8363\\\hline
    
    \end{tabular}
    \caption[BRISQUE]{BRISQUE Scores of original and generated images.}
    \end{center}
    \end{table}

Expectedly, the BRISQUE values for the generated images are always higher than
their original counterparts. "Logo" is not a photorealistic image to begin with, 
so it is understandable that the BRISQUE value is high at $102.9$.
None of the generated images would pass BRISQUE as photorealistic and free of 
distortions.  

Loss functions as well (MSE loss was used in GAN)


\subsection{GAN-Related Quantitative Metrics}

There are two prominent evaluation metrics for the performance of a Generative Adversarial Network (GAN).
Specifically, the Frechet Inception Distance (FID) and Inception Score (IS).

The FID score is 0 if there is no difference between the two multidimensional Gaussian distributions compared. 

Both measurements serve to evaluate the synthetic nature of the generated output. 


The \textbf{FID} score is presented in Table 3.1 below:

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
        \hline
    \textbf{Bevo}	& 1,241,999.901 \\
    \textbf{Kliment}	& 549,089.491\\
    \textbf{Logo}	& 81,105.162\\
    \textbf{Tower} & 331,171.556\\\hline
    
    \end{tabular}
    \caption[FID Score]{The Frechet Inception Distance (FID) score for all test images.}
    \end{center}
    \end{table}


The FID score can be used as a Loss functions as well, embedded within the architecture of the GAN.
However, it provides notoriously incosistent results, and is not as robut as MSE, which was used as 
the Loss function of choice for this project.

\section{Summary of Results}

\begin{center}
	\includegraphics[width=0.8\textwidth]{media/gan_compress2.png}
\end{center}

\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    \textbf{Image}	& \textbf{ViT-Score} & \textbf{SSIM} & \textbf{MSE} & \textbf{PSNR} & \textbf{FID}  & \textbf{BRISQUE} & \textbf{CR}\\
    \hline
    \textbf{Bevo}	 & 0.14 & 0.26 & 3,479.34  &  12.68  &  1,241,999.901  &  39.5535 & 0.75 \\
    \textbf{Kliment} & 0.54 & 0.56 & 1,759.28 & 15.64  &  549,089.491 & 44.3570 & 1.69\\
    \textbf{Logo}	 & 0.29 & 0.91 & 393.69 & 22.15 &  81,105.162 & 97.1844 & 0.12 \\
    \textbf{Tower}   & 0.03 & 0.53 & 1,315.75 & 16.90 &  331,171.556 & 52.8363 & 1.85\\\hline
    
    \end{tabular}
    \caption[Summary of Results]{ViT-Scores provide an insightful quality assessment compared to established methods.}
    \end{center}
    \end{table}
