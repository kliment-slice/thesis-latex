\section{Key Contributions}

(experimentation with Vision Transformers, nascent field)
Main merit of this thesis:
ViT-score, a ViT-Assisted metric for evaluating the performance of a neural image compression
Generative Adversarial Network.

This thesis explores a Vision Transformer (ViT)-Assisted metric related to 
image compression, which can provide 
additional insights to GAN output quality and the input latent space (contextual) preservation.

Furthermore, evaluating output quality from Generative Adversarial Networks (GANs) is 
still a developing field using non-Deep Learning-adapted assessment methods. 
For the purpose of this thesis, a GAN was used as a placeholder 
for a future, coveted, and highly desirable Deep Learning-based image compression mechanism. 

\NOTE{Thus, this work can be viewed as a stepping stone towards an end-to-end Transformer-based
image compression and regeneration.}

\section{Takeaways}

A Vision Transformer (ViT)-Assisted metric related to image compression can provide 
additional insights to the latent space (contextual) preservation.
Thus, this work can be viewed as a stepping stone towards an end-to-end Transformer-based
image compression and regeneration.

It will take 100M dollars and a lot of work from a giant tech company, but
future is near. The next major image compression methodology will be deep learning-based.
The next image quality assessment will be deep learning-based.
Transformers are ideal fit, highly generalizable, highly performant, hard to train.


\section{Acknowledgments}

The author would like to express gratitude towards several individuals and organizations
from The University of Texas at Austin campus.


The major inspiration for this project was gathered from two courses taught by the
reviewers of this thesis.


EE 371Q, Digital Image Processing taught by Professor Alan C. Bovik was the class
where the author learned about 
Image Compression, Image Quality Assessment, and completed a term
project on Generative Adversarial Networks.


CSE 382, Foundations of Machine Learning taught by Professor Rachel A. Ward 
was the class where the author learned key concepts used throughout this thesis
and completed a term project on Vision Transformers (ViT).


Further acknowledgments are made to the Laboratory for Image and Video Engineering (LIVE) at the 
University of Texas at Austin for providing a source for project inspiration and insights.


Finally, the author would like to express gratitude to The Texas Advanced Computing Center (TACC).
TACC provided free access to advanced High-Performance Computing (HPC) resources,
which were used throughout the experimentation process in this thesis.

\section{Closing Remarks}

This thesis is written as a graduation requirement for the degree of Master of Science 
in Computational Science, Engineering, and Mathematics awarded by the Oden Institute at 
The University of Texas at Austin.


All code and knowledge is available as open source to the general public.